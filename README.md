# Project_HandY_V2.0

Hey Students of 9D!

Hope you guys will like this Christmas Gift that you can use free of cost

If you use my code or snippets of it anywhere else in a Public domain,
Please credit me with my Github hyperlink :)

Have a Merry Christmas!

~ Nithish, 2022


Overview

As humans, We have always felt the need to interface the real world with the Virtual Environment. What better way to do that than controlling your cursor using your hands? And the best thing is that it doesn't require any external sensor. Only webcam input. That Is what I have created

Goals

To Make the Hand Detection module 80% Accurate: 
To translate Real-world XYZ Values to an XY Cartesian plane on which mouse data is derived from Hand Landmark Data: 

The Hand Detection and Landmark Allocation:

The Python Program uses a Tensorflow ML ( Machine Learning ) model that allocates 21 Landmarks to a hand in a webcam input.

The Landmark thatâ€™s XY Co-ordinate I require is the HandLandmark.INDEX_FINGER_TIP
This is then translated from default 3Dimensional Coordinates to normalized Pixel Coordinates

Milestones

Successfully implemented said Module!

Feels Flexible and Has many UseCase Scenarios

*Special Thanks to Nandan Manoharan of Class 9D for helping BETA-TEST the application.*
